{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8881488,"sourceType":"datasetVersion","datasetId":5344914},{"sourceId":8885556,"sourceType":"datasetVersion","datasetId":5346210}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:24:52.531452Z","iopub.execute_input":"2024-07-07T19:24:52.532317Z","iopub.status.idle":"2024-07-07T19:25:37.686680Z","shell.execute_reply.started":"2024-07-07T19:24:52.532282Z","shell.execute_reply":"2024-07-07T19:25:37.685768Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=728bcb8a2c688146ce22eadd3fe2c72db2dc5d2b01bc5d419edd6819f8b46be7\n  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql.functions import array_contains, col, lit, when, expr, size, array, explode, sum as spark_sum, udf\nfrom pyspark.sql.types import ArrayType, StringType, IntegerType, FloatType\nimport numpy as np\nimport logging\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:25:37.688882Z","iopub.execute_input":"2024-07-07T19:25:37.689249Z","iopub.status.idle":"2024-07-07T19:25:38.369228Z","shell.execute_reply.started":"2024-07-07T19:25:37.689214Z","shell.execute_reply":"2024-07-07T19:25:38.368345Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# REMA Project - Léo BILLANT - SCIA 2025","metadata":{}},{"cell_type":"markdown","source":"The code and most of its explanation/choices is in this notebook. The rest is in the README file. Thank you for reading !","metadata":{}},{"cell_type":"markdown","source":"# DATA LOADING","metadata":{}},{"cell_type":"code","source":"# Load MovieLens data\nmovies = pd.read_csv('/kaggle/input/movielens-ml1m/ml-1m/ml-1m/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'], encoding='ISO-8859-1')\nratings = pd.read_csv('/kaggle/input/movielens-ml1m/ml-1m/ml-1m/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'], encoding='ISO-8859-1')\n\n# Load IMDb data\nimdb_titles = pd.read_csv('/kaggle/input/movies/title.basics.tsv/title.basics.tsv', sep='\\t', low_memory=False)\nimdb_ratings = pd.read_csv('/kaggle/input/movies/title.ratings.tsv/title.ratings.tsv', sep='\\t', low_memory=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T19:25:38.370275Z","iopub.execute_input":"2024-07-07T19:25:38.370645Z","iopub.status.idle":"2024-07-07T19:26:27.060053Z","shell.execute_reply.started":"2024-07-07T19:25:38.370621Z","shell.execute_reply":"2024-07-07T19:26:27.059248Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPROCESSING","metadata":{}},{"cell_type":"code","source":"# We only want movies for a movie night, so we only keep movies\n\nimdb_titles = imdb_titles[imdb_titles['titleType'] == 'movie']\n\n# We don't want movies that are not at least a little popular on imdb\n\nimdb_ratings = imdb_ratings[imdb_ratings['numVotes'] > 500]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:27.061982Z","iopub.execute_input":"2024-07-07T19:26:27.062275Z","iopub.status.idle":"2024-07-07T19:26:30.046453Z","shell.execute_reply.started":"2024-07-07T19:26:27.062250Z","shell.execute_reply":"2024-07-07T19:26:30.045692Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Get the year of the movie from the title\n\ndef extract_year(title):\n    match = re.search(r'\\(\\d{4}\\)', title)\n    year = match.group(0)[1:-1] if match else ''\n    return year\n\nmovies['year'] = movies['title'].apply(extract_year)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:30.047545Z","iopub.execute_input":"2024-07-07T19:26:30.047830Z","iopub.status.idle":"2024-07-07T19:26:30.062215Z","shell.execute_reply.started":"2024-07-07T19:26:30.047806Z","shell.execute_reply":"2024-07-07T19:26:30.061367Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# To make sure that movies and imdb_titles merge well, we put the titles in the same form\n# For example, \"Women, The (1939)\" -> \"women the\" and \"The Women\" -> \"women the\"\n\ndef standardize_title(title):\n    if pd.isna(title):\n        return ''\n    title = re.sub(r'\\(\\d{4}\\)', '', title).strip().lower()\n    title = re.sub(r'[^a-z0-9\\s]', '', title)\n    if title.startswith('the '):\n        title = title[4:] + ' the'\n    return title\n\nmovies['title_small'] = movies['title'].apply(standardize_title)\nimdb_titles['primaryTitle'] = imdb_titles['primaryTitle'].apply(standardize_title)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:30.063479Z","iopub.execute_input":"2024-07-07T19:26:30.063869Z","iopub.status.idle":"2024-07-07T19:26:33.269074Z","shell.execute_reply.started":"2024-07-07T19:26:30.063839Z","shell.execute_reply":"2024-07-07T19:26:33.268156Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Merging the data\nmerged_data = pd.merge(movies, ratings, on='movieId')\nmerged_data = pd.merge(merged_data, imdb_titles, left_on=['title_small', 'year'], right_on=['primaryTitle', 'startYear'], how='left')\nmerged_data = pd.merge(merged_data, imdb_ratings, on='tconst', how='left')\n\n# If tconst was empty or removed by the previous filter (if titleType != movie), drop row\nmerged_data = merged_data.dropna(subset=['tconst'])\n\n# If numvotes was empty or removed by the previous filter (if numvotes < 500), drop row\nmerged_data = merged_data.dropna(subset=['numVotes'])\n\n# Imdb ratings are on a 0-10 scale. Let's put them on a 0-5 scale\nmerged_data['averageRating'] = merged_data['averageRating']/2\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:33.270336Z","iopub.execute_input":"2024-07-07T19:26:33.270763Z","iopub.status.idle":"2024-07-07T19:26:36.262377Z","shell.execute_reply.started":"2024-07-07T19:26:33.270729Z","shell.execute_reply":"2024-07-07T19:26:36.261365Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Extract genres from both datasets for each movie and combine them\ndef combine_genres(row):\n    genres_x = set(row['genres_x'].split('|'))\n    genres_y = set(row['genres_y'].split(','))\n    combined_genres = genres_x.union(genres_y)\n    combined_genres.discard('(no genres listed)')\n    return list(combined_genres)\n\nmerged_data['genres_combined'] = merged_data.apply(combine_genres, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:36.263589Z","iopub.execute_input":"2024-07-07T19:26:36.263857Z","iopub.status.idle":"2024-07-07T19:26:53.536435Z","shell.execute_reply.started":"2024-07-07T19:26:36.263834Z","shell.execute_reply":"2024-07-07T19:26:53.535654Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Drop irrelevant columns\nmerged_data = merged_data.drop(columns=['genres_x', 'genres_y', 'titleType', 'originalTitle', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes', 'timestamp','title_small', 'primaryTitle'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:53.537539Z","iopub.execute_input":"2024-07-07T19:26:53.537822Z","iopub.status.idle":"2024-07-07T19:26:53.648656Z","shell.execute_reply.started":"2024-07-07T19:26:53.537798Z","shell.execute_reply":"2024-07-07T19:26:53.647703Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Aggregate duplicate ratings by taking the mean rating\nmerged_data = merged_data.groupby(['userId', 'movieId']).agg({\n    'rating': 'mean',\n    'title': 'first',\n    'genres_combined': 'first',\n    'averageRating': 'first',\n    'numVotes': 'first',\n    'year': 'first'\n    \n}).reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:53.652869Z","iopub.execute_input":"2024-07-07T19:26:53.653143Z","iopub.status.idle":"2024-07-07T19:26:54.764020Z","shell.execute_reply.started":"2024-07-07T19:26:53.653114Z","shell.execute_reply":"2024-07-07T19:26:54.763258Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Be sure to not have any lacking data\nmerged_data =  merged_data.dropna(subset=['title'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:54.765086Z","iopub.execute_input":"2024-07-07T19:26:54.765385Z","iopub.status.idle":"2024-07-07T19:26:54.921927Z","shell.execute_reply.started":"2024-07-07T19:26:54.765359Z","shell.execute_reply":"2024-07-07T19:26:54.921155Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# We do not want biased movies in our model, so we take only movies with at least 50 reviews in movielens\n\n# Count occurrences of each movieId\nmovie_counts = merged_data['movieId'].value_counts()\n\n# Filter movieIds that appear more than 10 times\npopular_movieIds = movie_counts[movie_counts > 50].index\n\n# Filter ratings DataFrame based on popular movieIds\nfiltered_data = merged_data[merged_data['movieId'].isin(popular_movieIds)]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:54.922940Z","iopub.execute_input":"2024-07-07T19:26:54.923197Z","iopub.status.idle":"2024-07-07T19:26:55.001267Z","shell.execute_reply.started":"2024-07-07T19:26:54.923175Z","shell.execute_reply":"2024-07-07T19:26:55.000521Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# We do not want empty any movieId for the Als Algorithm, otherwise it will generate recommendations for movieId indices that are not present in the training data\n\n# Get unique ids\nunique_movieIds = sorted(filtered_data['movieId'].unique())\n\n# Replace movieId with a new one\nmovieId_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_movieIds)}\nfiltered_data.loc[:, 'movieId'] = filtered_data['movieId'].map(movieId_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:55.002632Z","iopub.execute_input":"2024-07-07T19:26:55.003126Z","iopub.status.idle":"2024-07-07T19:26:55.033608Z","shell.execute_reply.started":"2024-07-07T19:26:55.003094Z","shell.execute_reply":"2024-07-07T19:26:55.032890Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"filtered_data","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:55.034597Z","iopub.execute_input":"2024-07-07T19:26:55.034864Z","iopub.status.idle":"2024-07-07T19:26:55.061022Z","shell.execute_reply.started":"2024-07-07T19:26:55.034840Z","shell.execute_reply":"2024-07-07T19:26:55.060157Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        userId  movieId  rating                                      title  \\\n0            1        0     5.0                           Toy Story (1995)   \n1            1       39     5.0                          Pocahontas (1995)   \n2            1       88     5.0                           Apollo 13 (1995)   \n3            1      154     4.0  Star Wars: Episode IV - A New Hope (1977)   \n4            1      319     5.0                    Schindler's List (1993)   \n...        ...      ...     ...                                        ...   \n899276    6040     1968     2.0                          Caddyshack (1980)   \n899277    6040     2017     4.0                     Blazing Saddles (1974)   \n899278    6040     2025     4.0                        Blood Simple (1984)   \n899279    6040     2067     4.0                             Serpico (1973)   \n899280    6040     2075     4.0                         Chicken Run (2000)   \n\n                                          genres_combined  averageRating  \\\n0              [Comedy, Animation, Children's, Adventure]           4.15   \n1       [Drama, Musical, Animation, Children's, Romanc...           3.35   \n2                             [History, Drama, Adventure]           3.85   \n3                    [Action, Fantasy, Adventure, Sci-Fi]           4.30   \n4                        [Drama, War, History, Biography]           4.50   \n...                                                   ...            ...   \n899276                                    [Sport, Comedy]           3.60   \n899277                                  [Western, Comedy]           3.85   \n899278                [Drama, Crime, Film-Noir, Thriller]           3.75   \n899279                          [Drama, Crime, Biography]           3.85   \n899280         [Comedy, Animation, Children's, Adventure]           3.55   \n\n         numVotes  year  \n0       1076316.0  1995  \n1        204325.0  1995  \n2        317673.0  1995  \n3       1459641.0  1977  \n4       1461889.0  1993  \n...           ...   ...  \n899276   128004.0  1980  \n899277   153768.0  1974  \n899278   106010.0  1984  \n899279   136020.0  1973  \n899280   213354.0  2000  \n\n[882653 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>title</th>\n      <th>genres_combined</th>\n      <th>averageRating</th>\n      <th>numVotes</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>Toy Story (1995)</td>\n      <td>[Comedy, Animation, Children's, Adventure]</td>\n      <td>4.15</td>\n      <td>1076316.0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>39</td>\n      <td>5.0</td>\n      <td>Pocahontas (1995)</td>\n      <td>[Drama, Musical, Animation, Children's, Romanc...</td>\n      <td>3.35</td>\n      <td>204325.0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>88</td>\n      <td>5.0</td>\n      <td>Apollo 13 (1995)</td>\n      <td>[History, Drama, Adventure]</td>\n      <td>3.85</td>\n      <td>317673.0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>154</td>\n      <td>4.0</td>\n      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n      <td>[Action, Fantasy, Adventure, Sci-Fi]</td>\n      <td>4.30</td>\n      <td>1459641.0</td>\n      <td>1977</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>319</td>\n      <td>5.0</td>\n      <td>Schindler's List (1993)</td>\n      <td>[Drama, War, History, Biography]</td>\n      <td>4.50</td>\n      <td>1461889.0</td>\n      <td>1993</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>899276</th>\n      <td>6040</td>\n      <td>1968</td>\n      <td>2.0</td>\n      <td>Caddyshack (1980)</td>\n      <td>[Sport, Comedy]</td>\n      <td>3.60</td>\n      <td>128004.0</td>\n      <td>1980</td>\n    </tr>\n    <tr>\n      <th>899277</th>\n      <td>6040</td>\n      <td>2017</td>\n      <td>4.0</td>\n      <td>Blazing Saddles (1974)</td>\n      <td>[Western, Comedy]</td>\n      <td>3.85</td>\n      <td>153768.0</td>\n      <td>1974</td>\n    </tr>\n    <tr>\n      <th>899278</th>\n      <td>6040</td>\n      <td>2025</td>\n      <td>4.0</td>\n      <td>Blood Simple (1984)</td>\n      <td>[Drama, Crime, Film-Noir, Thriller]</td>\n      <td>3.75</td>\n      <td>106010.0</td>\n      <td>1984</td>\n    </tr>\n    <tr>\n      <th>899279</th>\n      <td>6040</td>\n      <td>2067</td>\n      <td>4.0</td>\n      <td>Serpico (1973)</td>\n      <td>[Drama, Crime, Biography]</td>\n      <td>3.85</td>\n      <td>136020.0</td>\n      <td>1973</td>\n    </tr>\n    <tr>\n      <th>899280</th>\n      <td>6040</td>\n      <td>2075</td>\n      <td>4.0</td>\n      <td>Chicken Run (2000)</td>\n      <td>[Comedy, Animation, Children's, Adventure]</td>\n      <td>3.55</td>\n      <td>213354.0</td>\n      <td>2000</td>\n    </tr>\n  </tbody>\n</table>\n<p>882653 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model Setup","metadata":{}},{"cell_type":"code","source":"# Initialize Spark session\nspark = SparkSession.builder.appName(\"CoupleRecommandations\").getOrCreate()\n\n# Load the filtered_data into a Spark DataFrame\nspark_df = spark.createDataFrame(filtered_data)\n\n# Extract unique genres\nunique_genres = set()\nfor genres in filtered_data['genres_combined']:\n    unique_genres.update(genres)\n\n# Create a one-hot encoding for genres\nfor genre in unique_genres:\n    spark_df = spark_df.withColumn(genre, when(array_contains(col('genres_combined'), genre), 1).otherwise(0))\n\nspark_df = spark_df.repartition(200)\nspark_df.cache()\n\n# Creating a User-Item Interaction Matrix for ALS\nindexer = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in [\"userId\", \"movieId\"]]\npipeline = Pipeline(stages=indexer)\ntransformed = pipeline.fit(spark_df).transform(spark_df)\n\n# Ensure transformed DataFrame retains necessary columns\nspark_df = transformed.select(\"userId\", \"movieId\", \"rating\", \"title\", \"genres_combined\", \"averageRating\", \"numVotes\", \"movieId_index\", \"year\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:26:55.062148Z","iopub.execute_input":"2024-07-07T19:26:55.062432Z","iopub.status.idle":"2024-07-07T19:28:51.604620Z","shell.execute_reply.started":"2024-07-07T19:26:55.062407Z","shell.execute_reply":"2024-07-07T19:28:51.603513Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/07/07 19:26:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n24/07/07 19:28:25 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n24/07/07 19:28:26 WARN TaskSetManager: Stage 0 contains a task of very large size (20248 KiB). The maximum recommended task size is 1000 KiB.\n                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Split data into training and test sets\n(training, test) = transformed.randomSplit([0.8, 0.2], seed=42)\n\n# ALS model\nals = ALS(\n    maxIter=10,\n    regParam=0.1,\n    rank=20,\n    userCol=\"userId_index\",\n    itemCol=\"movieId_index\",\n    ratingCol=\"rating\",\n    coldStartStrategy=\"drop\",\n    nonnegative=True\n)\n\n# Training\nmodel = als.fit(training)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:28:51.606935Z","iopub.execute_input":"2024-07-07T19:28:51.607305Z","iopub.status.idle":"2024-07-07T19:29:15.551625Z","shell.execute_reply.started":"2024-07-07T19:28:51.607269Z","shell.execute_reply":"2024-07-07T19:29:15.550818Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"24/07/07 19:29:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"# Rating for Single Users","metadata":{}},{"cell_type":"code","source":"max_rating = 5\nmin_rating = 0\n\n# Force ALS Score to be between 0 and 5\ndef clip_score(score):\n    return min(max(score, min_rating), max_rating)\n\nclip_udf = udf(clip_score, FloatType())","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:29:15.553211Z","iopub.execute_input":"2024-07-07T19:29:15.553858Z","iopub.status.idle":"2024-07-07T19:29:15.561577Z","shell.execute_reply.started":"2024-07-07T19:29:15.553830Z","shell.execute_reply":"2024-07-07T19:29:15.560661Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Get the individual score for ALS\ndef get_top_n_recommendations(user_id, n, model):\n    user_recs = model.recommendForUserSubset(spark.createDataFrame([(user_id,)], [\"userId_index\"]), n)\n    user_recs = user_recs.withColumn(\"rec\", explode(\"recommendations\"))\n    user_recs = user_recs.select(\"userId_index\", col(\"rec.movieId_index\").alias(\"movieId_index\"), col(\"rec.rating\").alias(\"score\"))\n    user_recs = user_recs.withColumn(\"score\", clip_udf(col(\"score\")))\n    return user_recs","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:29:15.562912Z","iopub.execute_input":"2024-07-07T19:29:15.563641Z","iopub.status.idle":"2024-07-07T19:29:15.572036Z","shell.execute_reply.started":"2024-07-07T19:29:15.563607Z","shell.execute_reply":"2024-07-07T19:29:15.570726Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Get the individual recommendation for one user\ndef recommend_for_single_user(user_id, n, model, spark_df, filtered_data):\n    # Get top N recommendations for the user\n    user_recs = get_top_n_recommendations(user_id, n, model)\n    \n    # Convert Spark DataFrame to Pandas DataFrame\n    user_recs_pd = user_recs.toPandas()\n    \n    # Sort and display the top 10 recommendations\n    user_recs_pd = user_recs_pd.sort_values(by='score', ascending=False).head(10)\n    \n    # Join with filtered_data to get the titles and other details\n    user_recs_pd = user_recs_pd.merge(filtered_data, how='left', left_on='movieId_index', right_on='movieId').drop_duplicates(subset=[\"movieId_index\", \"score\"])\n    \n    # Display recommendations\n    print(f\"Recommendations for user {user_id}:\")\n    print(user_recs_pd[['title', 'score']])\n\n# Example usage for single user\nuser1_id = 1\nrecommend_for_single_user(user1_id, 10, model, spark_df, filtered_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:29:15.576120Z","iopub.execute_input":"2024-07-07T19:29:15.576442Z","iopub.status.idle":"2024-07-07T19:29:19.639868Z","shell.execute_reply.started":"2024-07-07T19:29:15.576412Z","shell.execute_reply":"2024-07-07T19:29:19.638891Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"[Stage 173:>                                                        (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"Recommendations for user 1:\n                             title     score\n0                     Shaft (1971)  4.541117\n222            Superman III (1983)  4.467391\n733      Addams Family, The (1991)  4.454474\n1447      Leaving Las Vegas (1995)  4.429168\n2427  Devil in a Blue Dress (1995)  4.423054\n2806  Gentleman's Agreement (1947)  4.394519\n2897     Body Snatcher, The (1945)  4.391973\n2961  Home for the Holidays (1995)  4.390656\n3060                  Balto (1995)  4.381446\n3159   Natural Born Killers (1994)  4.375618\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"# Rating for Couples","metadata":{}},{"cell_type":"code","source":"# Get favorite movie genres for one user\ndef get_favorite_genres(user_id):\n    user_genres = merged_data[merged_data['userId'] == user_id]['genres_combined'].explode().value_counts()\n    return list(user_genres.nlargest(5).index)\n\n# Get favorite movie year/era for one user\ndef get_favorite_year(user_id):\n    # Filter the data for the given user to get the years of the movies they watched\n    user_data = merged_data[merged_data['userId'] == user_id]\n    watched_years = user_data['year']\n    \n    # Here I chose to do median instead of mean to not have really old classics and brand new blockbusters that everyone has seen bias the result\n    return int(np.median(watched_years))\n    \n    \n# Get movie recommendations for a date night for 2 users\ndef recommend_for_couple(user1_id, user2_id, model, spark_df, merged_data, filtered_data, n=1000):\n    # Get ALS recommendations for each user\n    user1_recs = get_top_n_recommendations(user1_id, n, model).withColumnRenamed(\"score\", \"score_user1\")\n    user2_recs = get_top_n_recommendations(user2_id, n, model).withColumnRenamed(\"score\", \"score_user2\")\n    \n    # Combine the ALS recommendations\n    combined_recs = user1_recs.join(user2_recs, \"movieId_index\", \"outer\")\n    combined_recs = combined_recs.withColumn(\"als_score\", \n                                             (when(col(\"score_user1\").isNull(), 0).otherwise(col(\"score_user1\")) + \n                                              when(col(\"score_user2\").isNull(), 0).otherwise(col(\"score_user2\"))) / 2)\n    \n    # Get favorite genres for each user\n    user1_genres = get_favorite_genres(user1_id)\n    user2_genres = get_favorite_genres(user2_id)\n    \n    # Keep the favorite genres that the 2 users have in common\n    favorite_genres = list(set(user1_genres).intersection(set(user2_genres)))\n    \n    # Put year in the good format    \n    merged_data['year'] = merged_data['title'].str.extract(r'\\((\\d{4})\\)').astype(float)\n    spark_df = spark_df.withColumn(\"year\", col(\"year\").cast(\"float\"))\n    \n    # Get favorite movie year for each user\n    user1_year = get_favorite_year(user1_id)\n    user2_year = get_favorite_year(user2_id)\n    \n    # Take the mean of both users favorite year\n    # We don't use the median for every movie because we want both of the users to be satisfied\n    favorite_year = (user1_year + user2_year) / 2\n    \n    # Join with movie details\n    combined_recs = combined_recs.join(spark_df.select(\"movieId_index\", \"genres_combined\", \"averageRating\", \"title\", \"numVotes\", \"year\"), \"movieId_index\", \"left\").dropDuplicates([\"movieId_index\", \"als_score\"])\n    \n    # Filter out movies that either user has already watched\n    watched_movies_user1 = filtered_data[filtered_data['userId'] == user1_id]['movieId'].unique()\n    watched_movies_user2 = filtered_data[filtered_data['userId'] == user2_id]['movieId'].unique()\n    watched_movies = set(watched_movies_user1).union(set(watched_movies_user2))\n    combined_recs = combined_recs.filter(~col(\"movieId_index\").isin(watched_movies))\n    \n    # Create a UDF to calculate matching genres\n    @udf(returnType=FloatType())\n    def calculate_genre_score(genres, favorite_genres):\n        if not genres or not favorite_genres:\n            return 0.0\n\n        genre_set = set(genres)\n        favorite_set = set(favorite_genres)\n\n        matching_genres = len(genre_set.intersection(favorite_set))\n        total_favorites = len(favorite_set)\n        \n        # We check how many favorite genres are present\n        return matching_genres / total_favorites\n    \n    # Create a UDF to calculate matching year\n    @udf(returnType=FloatType())\n    def calculate_year_score(movie_year, favorite_year):\n        if not movie_year or not favorite_year:\n            return 0.0\n\n        year_difference = abs(movie_year - favorite_year)\n        \n        # Score calculation : 30 years maximum otherwise it's too far from the liked era. Each year difference represents 3.33% of the score.\n        score = max(0.0, (30 - year_difference) / 30)\n        return score\n    \n    \n    # Calculate genre match score\n    combined_recs = combined_recs.withColumn(\"genre_score\", \n                                             calculate_genre_score(col(\"genres_combined\"), array(*[lit(g) for g in favorite_genres])))\n    \n    # Calculate year match score\n    combined_recs = combined_recs.withColumn(\"year_score\", calculate_year_score(col(\"year\"), lit(favorite_year)))\n    \n    \n    # Calculate final score :\n    # als_score is the most relevent as we trained the model. It is also the center of this exercise.\n    # averageRating of imDb is also quite relevant as imdb is a worlwide reference in movie ranking\n    # genre_score is only at 0.1 because it creates a very strong bias. Putting more would be pretty much the same as filtering the genres to only get all of the favorites genres\n    # year_score is only at 0.1, because it is not as relevant as the rest\n    combined_recs = combined_recs.withColumn(\"final_score\", \n                                             0.6 * col(\"als_score\") + \n                                             0.1 * col(\"genre_score\") * 5 + \n                                             0.2 * col(\"averageRating\") +\n                                             0.1 * col(\"year_score\") * 5\n                                            )\n    \n    # Sort by final score and get the top 5 movies\n    top_movies = combined_recs.orderBy(col(\"final_score\").desc()).limit(5)\n\n    # Collect the top 5 movies\n    top_movies_list = top_movies.collect()\n\n    print(f\"Favorites genres of the couple {favorite_genres}:\")\n    print(f\"Favorites year of the couple {favorite_year}:\")\n\n    # Extract and print details of the top 5 movies\n    for idx, movie in enumerate(top_movies_list):\n        print(f\"\\nTop {idx + 1} movie recommendation for users {user1_id} and {user2_id}:\")\n        print(f\"Title: {movie['title']}\")\n        print(f\"Genres: {movie['genres_combined']}\")\n        print(f\"IMDb Rating: {movie['averageRating']} / 5\")\n        print(f\"ALS Score: {movie['als_score']} / 5\")\n        print(f\"Genre Score: {movie['genre_score']*5} / 5\")\n        print(f\"Year Score: {movie['year_score']*5} / 5\")\n        print(f\"Predicted rating for the couple: {movie['final_score']:.2f} / 5\")\n        \n        \n\n# Example usage for a date night for user 1 and 2\nuser1_id = 1\nuser2_id = 2\nrecommend_for_couple(user1_id, user2_id, model, spark_df, merged_data, filtered_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:29:19.641618Z","iopub.execute_input":"2024-07-07T19:29:19.642200Z","iopub.status.idle":"2024-07-07T19:29:36.609899Z","shell.execute_reply.started":"2024-07-07T19:29:19.642164Z","shell.execute_reply":"2024-07-07T19:29:36.608436Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"[Stage 339:==============>                                          (1 + 3) / 4]\r","output_type":"stream"},{"name":"stdout","text":"Favorites genres of the couple ['Adventure', 'Drama']:\nFavorites year of the couple 1991.0:\n\nTop 1 movie recommendation for users 1 and 2:\nTitle: Schindler's List (1993)\nGenres: ['Drama', 'War', 'History', 'Biography']\nIMDb Rating: 4.5 / 5\nALS Score: 4.200810432434082 / 5\nGenre Score: 2.5 / 5\nYear Score: 4.666666686534882 / 5\nPredicted rating for the couple: 4.14 / 5\n\nTop 2 movie recommendation for users 1 and 2:\nTitle: Shawshank Redemption, The (1994)\nGenres: ['Drama']\nIMDb Rating: 4.65 / 5\nALS Score: 4.112240791320801 / 5\nGenre Score: 2.5 / 5\nYear Score: 4.4999998807907104 / 5\nPredicted rating for the couple: 4.10 / 5\n\nTop 3 movie recommendation for users 1 and 2:\nTitle: Lion King, The (1994)\nGenres: ['Drama', 'Musical', 'Animation', \"Children's\", 'Adventure']\nIMDb Rating: 4.25 / 5\nALS Score: 3.750603675842285 / 5\nGenre Score: 5.0 / 5\nYear Score: 4.4999998807907104 / 5\nPredicted rating for the couple: 4.05 / 5\n\nTop 4 movie recommendation for users 1 and 2:\nTitle: Silence of the Lambs, The (1991)\nGenres: ['Drama', 'Crime', 'Thriller']\nIMDb Rating: 4.3 / 5\nALS Score: 4.046184539794922 / 5\nGenre Score: 2.5 / 5\nYear Score: 5.0 / 5\nPredicted rating for the couple: 4.04 / 5\n\nTop 5 movie recommendation for users 1 and 2:\nTitle: Stand by Me (1986)\nGenres: ['Drama', 'Comedy', 'Adventure']\nIMDb Rating: 4.05 / 5\nALS Score: 3.831657886505127 / 5\nGenre Score: 5.0 / 5\nYear Score: 4.166666567325592 / 5\nPredicted rating for the couple: 4.03 / 5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluate the model for rmse\nevaluator_rmse = RegressionEvaluator(\n    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n)\n\n# Evaluate the model for mae\nevaluator_mae = RegressionEvaluator(\n    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n)\npredictions = model.transform(test)\nrmse = evaluator_rmse.evaluate(predictions)\nmae = evaluator_mae.evaluate(predictions)\n\nprint(\"RMSE=\" + str(rmse))\nprint(f\"MAE = {mae}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T19:29:36.611007Z","iopub.execute_input":"2024-07-07T19:29:36.611342Z","iopub.status.idle":"2024-07-07T19:29:53.406203Z","shell.execute_reply.started":"2024-07-07T19:29:36.611309Z","shell.execute_reply":"2024-07-07T19:29:53.405262Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"RMSE=0.8669688747568868\nMAE = 0.6957531818563544\n","output_type":"stream"}]}]}